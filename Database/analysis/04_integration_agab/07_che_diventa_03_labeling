#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import json
import time
from pathlib import Path
from typing import Optional, Dict, List

import pandas as pd
import requests

# =========================
# PATHS
# =========================

BASE_DIR = Path("/doctorai/chiarba/AbAg_database/clean")
INPUT_CSV = BASE_DIR / "agab_cdr3_annotated1.csv"
OUTPUT_CSV = BASE_DIR / "annotation" / "agab_cdr3_annotated1_with_origin.csv"

CACHE_DIR = BASE_DIR
UNIPROT_CACHE_PATH = CACHE_DIR / "uniprot_cache.json"
PDB_ENTITY_CACHE_PATH = CACHE_DIR / "pdb_antigen_entity_cache.json"

# =========================
# HTTP / CACHE
# =========================

TIMEOUT = 15
REQS_PER_SEC = 5

_session = None
_last_call_ts = 0.0

def get_session() -> requests.Session:
    global _session
    if _session is None:
        s = requests.Session()
        _session = s
    return _session

def throttle():
    """Limit request rate to external APIs."""
    global _last_call_ts
    min_interval = 1.0 / max(1, REQS_PER_SEC)
    now = time.time()
    sleep_s = min_interval - (now - _last_call_ts)
    if sleep_s > 0:
        time.sleep(sleep_s)
    _last_call_ts = time.time()

def load_json_cache(path: Path) -> dict:
    if path.exists():
        try:
            with open(path, "r") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def save_json_cache(path: Path, obj: dict):
    try:
        with open(path, "w") as f:
            json.dump(obj, f)
    except Exception:
        pass

UNIPROT_CACHE: Dict[str, dict] = load_json_cache(UNIPROT_CACHE_PATH)
PDB_ENTITY_CACHE: Dict[str, List[str]] = load_json_cache(PDB_ENTITY_CACHE_PATH)

# =========================
# BASIC UTILS
# =========================

def norm(x: Optional[str]) -> str:
    if x is None:
        return ""
    if not isinstance(x, str):
        x = str(x)
    return x.strip()

def looks_like_uniprot_acc(x: str) -> bool:
    x = norm(x).upper()
    if not x:
        return False
    return bool(re.fullmatch(r"[A-Z0-9]{6,10}", x))

def looks_like_pdb_id(x: str) -> bool:
    x = norm(x)
    return bool(re.fullmatch(r"[0-9A-Za-z]{4}", x))

# =========================
# UNIPROT LOOKUP
# =========================

def uniprot_fetch_min(acc: str) -> dict:
    """
    Minimal UniProt fetch: organism name, taxid (int), lineage list.
    Uses cache. If cached is empty or broken, re-query UniProt.
    """
    acc = norm(acc).upper()

    # ---- cache check ----
    cached = UNIPROT_CACHE.get(acc)
    if isinstance(cached, dict) and cached:
        # use cache only if it has at least organism or taxid
        if cached.get("organism") or cached.get("taxid") is not None:
            return cached
        # otherwise ignore it and re-fetch

    # ---- fresh query to UniProt ----
    sess = get_session()
    url = f"https://rest.uniprot.org/uniprotkb/{acc}.json"
    try:
        throttle()
        r = sess.get(url, timeout=TIMEOUT)
        if r.status_code != 200:
            UNIPROT_CACHE[acc] = {}
            save_json_cache(UNIPROT_CACHE_PATH, UNIPROT_CACHE)
            return {}
        rec = r.json()
    except Exception:
        UNIPROT_CACHE[acc] = {}
        save_json_cache(UNIPROT_CACHE_PATH, UNIPROT_CACHE)
        return {}

    org = (rec.get("organism") or {})
    organism_name = org.get("scientificName")

    # force taxid to int when possible
    taxid_raw = org.get("taxonId")
    if isinstance(taxid_raw, int):
        taxid = taxid_raw
    else:
        try:
            taxid = int(str(taxid_raw)) if taxid_raw is not None else None
        except Exception:
            taxid = None

    lineage_list = org.get("lineage") or []

    out = {
        "organism": organism_name,
        "taxid": taxid,
        "lineage": lineage_list,
    }
    UNIPROT_CACHE[acc] = out
    save_json_cache(UNIPROT_CACHE_PATH, UNIPROT_CACHE)
    return out

# =========================
# PDB ENTITY → UNIPROT FOR ANTIGEN
# =========================

def score_description(desc: str, name_hint: str) -> int:
    """Crude similarity score between PDB entity description and antigen/name_hint."""
    desc = (desc or "").lower()
    name_hint = (name_hint or "").lower()
    if not desc or not name_hint:
        return 0

    score = 0
    # strong bonus for substring match
    if name_hint in desc or desc in name_hint:
        score += 5

    # token overlap
    tokens = [t for t in re.findall(r"[a-z0-9]+", name_hint) if len(t) >= 3]
    for t in tokens:
        if t in desc:
            score += 1

    return score


def pdb_antigen_uniprots_from_entities(pdb_id: str, name_hint: str, max_entities: int = 10) -> list:
    """
    Usa RCSB polymer_entity per trovare l'entity più simile all'antigene (name_hint).
    Ritorna una lista di "item" del tipo:
      - {"kind": "uniprot", "acc": "P15692"}
      - {"kind": "taxonomy", "taxid": 9606, "organism": "Homo sapiens"}

    Quindi:
      * se ci sono UniProt → li usiamo
      * se NON ci sono UniProt → usiamo direttamente i source_organism_ids del PDB
    """
    key = f"{pdb_id.lower()}|{name_hint.lower()}"
    if key in PDB_ENTITY_CACHE:
        return PDB_ENTITY_CACHE[key]

    sess = get_session()
    best_score = -1
    best_items: list = []

    for ent in range(1, max_entities + 1):
        url = f"https://data.rcsb.org/rest/v1/core/polymer_entity/{pdb_id}/{ent}"
        try:
            throttle()
            r = sess.get(url, timeout=TIMEOUT)
        except Exception:
            break

        if r.status_code == 404:
            # non ci sono altre entity
            break
        if r.status_code != 200:
            continue

        try:
            data = r.json()
        except Exception:
            continue

        # descrizione per scoring antigene
        pe = data.get("rcsb_polymer_entity") or {}
        ep = data.get("entity_poly") or {}
        desc = pe.get("pdbx_description") or ep.get("pdbx_description") or ""

        s = score_description(desc, name_hint)
        if s <= best_score:
            continue

        # raccogliamo info per questa entity
        items: list = []

        # 1) UniProt se presenti
        cont = data.get("rcsb_polymer_entity_container_identifiers") or {}
        refs = cont.get("reference_sequence_identifiers") or []
        for ref in refs:
            if (ref.get("database_name") or "").lower() == "uniprot":
                acc = ref.get("database_accession")
                if acc:
                    items.append({"kind": "uniprot", "acc": acc.upper()})

        # 2) Se non ci sono UniProt → tassonomia dal PDB
        if not items:
            tax_ids = pe.get("source_organism_ids") or []
            sci_names = pe.get("source_scientific_name") or []
            if tax_ids:
                items.append(
                    {
                        "kind": "taxonomy",
                        "taxid": int(tax_ids[0]),
                        "organism": sci_names[0] if sci_names else "",
                    }
                )

        if not items:
            # nessuna info utile per questa entity
            continue

        best_score = s
        best_items = items

    PDB_ENTITY_CACHE[key] = best_items
    save_json_cache(PDB_ENTITY_CACHE_PATH, PDB_ENTITY_CACHE)
    return best_items


# =========================
# CLASSIFICATION LOGIC
# =========================

def classify_by_text(name: str) -> str:
    """Text-based heuristic when no taxonomy is available."""
    txt = (name or "").lower()

    # Viral keywords
    if any(k in txt for k in [
        "virus", "viral", "sars-cov2", "sars cov2", "covid-19",
        "orf", "polyprotein", "gag-pol", "hemagglutinin", "nucleoprotein",
        "envelope glycoprotein"
    ]):
        return "viral"

    # Bacterial hints
    if any(k in txt for k in [
        "escherichia coli", "e. coli", "staphylococcus", "streptococcus",
        "mycobacterium", "pseudomonas", "salmonella", "bacillus"
    ]):
        return "bacteria"

    # Non-human mammals → keep as other
    if any(k in txt for k in [
        "_mouse", " mouse", "mus musculus",
        " rat ", "rattus norvegicus"
    ]):
        return "other"

    # Explicit human hints
    if "human" in txt or "homo sapiens" in txt:
        return "human"

    return "other"


def classify_by_taxonomy(
    taxid: Optional[int],
    organism: Optional[str],
    lineage_list: Optional[list],
    name_hint: str = "",
) -> str:
    """Human / viral / bacteria / other based on taxonomy + name."""
    organism = (organism or "").lower()
    lineage = "; ".join(lineage_list or []).lower()
    name_hint = (name_hint or "").lower()

    # Human: taxid OR organism name
    if taxid == 9606 or "homo sapiens" in organism or "human" in organism:
        return "human"

    # Viral
    if "virus" in organism or "viruses" in lineage:
        return "viral"
    if any(k in name_hint for k in ["sars-cov2", "sars-cov-2", "covid-19", "orf", "polyprotein"]):
        return "viral"

    # Bacteria
    if "bacteria" in lineage or "bacterium" in organism:
        return "bacteria"

    return "other"

def classify_origin_row(target_uniprot: str,
                        target_pdb: str,
                        target_name: str,
                        antigen: str) -> str:
    """
    Nuova logica:

    1) PROVA CON IL TESTO (target_name + antigen)
       - se il testo suggerisce chiaramente human/viral/bacteria → usa quello
    2) SE IL TESTO È POCO INFORMATIVO (other)
       - se c'è target_uniprot → usa tassonomia UniProt
    3) SE UNIPROT È VUOTO O NON AIUTA
       - se c'è target_pdb → usa PDB (entity → UniProt) per risalire all'organismo
    4) se ancora niente → other
    """

    tn = norm(target_name)
    ag = norm(antigen)
    tu = norm(target_uniprot)
    tp = norm(target_pdb)

    # ---------- 1) TESTO: target_name + antigen ----------
    name_hint = f"{tn} {ag}".strip()
    if name_hint:
        cls_text = classify_by_text(name_hint)
        # se dal testo emerge chiaramente human / viral / bacteria, ci fidiamo
        if cls_text in {"human", "viral", "bacteria"}:
            return cls_text
        # se è other, continuiamo con le sorgenti DB

    # ---------- 2) UNIPROT: target_uniprot ----------
    if tu and looks_like_uniprot_acc(tu):
        info = uniprot_fetch_min(tu)
        if info:
            cls_uni = classify_by_taxonomy(
                info.get("taxid"),
                info.get("organism"),
                info.get("lineage") or [],
                name_hint=name_hint,
            )
            # qualunque cosa esca da UniProt la usiamo (anche human/viral/bacteria)
            if cls_uni in {"human", "viral", "bacteria"}:
                return cls_uni
            # se è other lasciamo la possibilità al PDB di dire qualcosa di più

        # 3) PDB entity-based mapping
    if tp and looks_like_pdb_id(tp):
        items = pdb_antigen_uniprots_from_entities(tp, name_hint)
        if items:
            priority = {"human": 0, "viral": 1, "bacteria": 2, "other": 3}
            best_class = None
            best_rank = 999

            for raw in items:
                # compatibilità: se in cache ci sono ancora stringhe,
                # trattale come UniProt accessions
                if isinstance(raw, dict):
                    item = raw
                else:
                    item = {"kind": "uniprot", "acc": str(raw)}

                kind = item.get("kind")

                if kind == "uniprot":
                    info = uniprot_fetch_min(item["acc"])
                    if not info:
                        continue
                    cls = classify_by_taxonomy(
                        info.get("taxid"),
                        info.get("organism"),
                        info.get("lineage") or [],
                        name_hint=name_hint,
                    )

                elif kind == "taxonomy":
                    cls = classify_by_taxonomy(
                        item.get("taxid"),
                        item.get("organism"),
                        [],
                        name_hint=name_hint,
                    )
                else:
                    continue

                rank = priority.get(cls, 3)
                if rank < best_rank:
                    best_rank = rank
                    best_class = cls
                if best_rank == 0:  # human → migliore possibile
                    break

            if best_class is not None:
                return best_class

    # ---------- 4) fallback finale ----------
    # se siamo arrivati qui, né testo, né UniProt, né PDB hanno dato info utili
    return "other"

# =========================
# MAIN
# =========================

# =========================
# MAIN
# =========================

def main():
    if not INPUT_CSV.exists():
        raise SystemExit(f"Input not found: {INPUT_CSV}")

    df = pd.read_csv(INPUT_CSV)

    required_cols = {"target_name", "target_pdb", "target_uniprot", "antigen"}
    missing = required_cols - set(df.columns)
    if missing:
        raise SystemExit(f"Missing columns in {INPUT_CSV}: {missing}")

    # Here we use the full dataset (no head(1000), no test mode)
    print(f"Loaded {len(df)} rows from {INPUT_CSV}")

    origins = []
    for i, row in df.iterrows():
        origin = classify_origin_row(
            target_uniprot=row.get("target_uniprot", ""),
            target_pdb=row.get("target_pdb", ""),
            target_name=row.get("target_name", ""),
            antigen=row.get("antigen", ""),
        )
        origins.append(origin)
        if (i + 1) % 1000 == 0:
            print(f"[{i+1}/{len(df)}] rows processed", flush=True)

    df["origin_class"] = origins

    OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"Saved with origin_class to: {OUTPUT_CSV}")


if __name__ == "__main__":
    # Optional: you can remove this debug if you do not need it anymore
    # info = uniprot_fetch_min("P78324")
    # print("DEBUG P78324:", info)
    main()
